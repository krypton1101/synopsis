---
date: 2024-10-29
tags:
  - theory
  - applied_statistics_methods
---
Случайные величины ($X,Y$) могут быть:
- независимыми
- зависимыми
  - функционально ($Y=f(X)$)
  - стохастически (есть посторонние факторы)
    - корреляционно ($X$ оказывает влияние на $M(Y)$)
    - некорреляционно

Статистической зависимостью называется такая зависимость, при которой изменение одной из величин влечет за собой изменение распределения другой.
Если при изменении одной из величин изменяется среднее значение другой, то статистическая зависимость называется корреляционной.
СВ, связанные корреляционной зависимостью, называются коррелированными.

Задача корреляционного анализа - установить тип зависимости.
Задача регрессионного анализа - описать эту связь аналитической зависимостью (с помощью уравнения).

Коэффициенты корреляции
1. Для порядковых данных
   $\rho$ - коэффицент ранговой корреляции Спирмена
   $\tau$ - коэффициент ранговой корреляции Кендалла
2. Для переменных с интервальной и номинальной шкалой
   коэффицент корреляции Пирсона

### Выборочный коэффициент корреляции Пирсона
Сравниваемые переменные должны быть получены в интервальной шкале или шкале отношений.
Распределения СВ должны быть близки к нормальным.
Число варьирующих признаков в сравниваемых переменных должно быть одинаково.

Свойства:
- Характеризует степень линейной связи двух признаков
- Изменяется от -1 до 1
- Близость к 1 по модулю говорит о высокой степени линйеной зависимости
- $Y=aX+b$ при $r_{B}=1$
- При $r_{B}$ случайные величины либо независимы, либо некоррелированные
- Знак обозначает положительную или отрицательную корреляцию признаков

#### Проверка независимости двух признаков
$H_{0}:r_{xy}=0$, $H_1:r_{xy}\neq0$
Критерий Стьюдента $T=\frac{R_{B}\sqrt{n-2}}{\sqrt{1-R_{B}^{2}}}$
Полученное значение сравнивается с критическим значением при заданном уровне значимости и числе степеней свободы $n-2$. Если $r_{xy}\neq0$, делается вывод о независимости величин.

### Парный регрессионный анализ
$y=\alpha+\beta x+ u$
$y$ - зависимая переменная, состоит из:
1. неслучаной составляющей $\alpha+ \beta x$, где $x$ - объсняющая (независимая) переменная, $\alpha, \beta$ - параметры уравнения
2. случайной составляющей $u$ с распреелением $N(0,1)$.
   Чтобы исключить случайную составляющую уравнение линейной регрессии ищут в виде $\overline{y}=\alpha+\beta x$.

$S=\sum\limits(bx_{i}+a-y_{i})^{2}\to \min$

Коэффициент коррелляции Пирсона вычисляется по формуле $$r_{B}=\frac{\sum\limits(x_{i}-\overline{x})(y_{i}-\overline{y})}{\sqrt{\sum\limits(x_{i}-\overline{x})^{2})}\sqrt{\sum\limits(y_{i}-\overline{y})^{2}}}$$
$\rho_{xy}=\beta=r_{B}\frac{s_{y}}{s_{x}}$, где $s_{x},s_{y}$ - выборочные дисперсии по $x,y$ - выборочный коэффициент регрессии.
$\alpha=\overline{y}-\rho_{yx}\overline{x}$

$\widetilde{y}$ - $y$ относящееся к уравнению регрессии.
$\widetilde{y}=\alpha+\beta x=\overline{y}+\rho_{yx}(x-\overline{x})$

#### Оценка качества модели линейной регрессии
Остаточная дисперсия $\widetilde{s}^{2}=\frac{1}{n_{2}}\sum\limits_{i=1}^{n}(y-\overline{y})^{2}$ - характеристика разброса значений $y$ относительно линии регрессии. Чем меньше остаточная дисперсия, тем ближе функция регрессии к исходным данным.
Остаточная дисперсия связана с коэффициентом корреляяции равенством $\widetilde{s}=\frac{n-1}{n-2}s^{2}_{y}(1-r_{B}^{2})$.

Второй способ - оценка отклонений фактических и рассчетных значений относительно амплитуды исходных данных. Если количество отклонений, б*о*льших 20% от амплитуды больше 80%, регрессия считается не надежным.

#### Проверка гипотез о параметрах уравнения регрессии
Критерий для проверки $b$: $$t_{b}=\frac{\beta-b_{0}}{s_{\beta}}$$
$$s_\beta=\frac{\widetilde{s}}{\sqrt{(n-1)s_{x}^{2}}}$$
Критерий для проверки $a$: $$t_{a}=\frac{\alpha-a_{0}}{s_{a}}$$
$$s_{a}=\widetilde{s}\sqrt{\frac{1}{n}+\frac{\overline{x}}{(n-1)s^{2}_{x}}}$$
Распределение Стьюдента с $n-2$ степенями свободы.
## Ранговая корреляция
### Коэффициент ранговой корреляции Спирмена
Два качественных признака ранжируются.
Рангвоый коэффициент корреляции Спирмена: $$\rho=1-\frac{6\sum\limits_{i=1}^{n}d_{i}^{2}}{n^{3}-n}$$
где $d_{i}=x_{i}-y_{i}$ - разница рангов сравниваемых величин, $n$ - число сравниваемых пар.
#### Проверка значимости
Если $n>50$, используется критерий Стьюдента $T=\frac{\rho}{\sqrt{1-\rho}}\sqrt{n-2}$, имеющий распределение Стьюдента со степенями свободы $n-2$.
Если $\vert T_\text{набл}\vert<t_\text{кр}$, нулевая гипотеза $\rho=0$ принимается.

### Коэффициент ранговой корреляции Кендалла
Используется, если связанные ранги отсутствуют.
$\tau=2\frac{\sum\limits P-\sum\limits Q}{n(n-1)}$
$P$ - количество рангов значения Y больше текущего из объектов, где ранг значения X больше текущего
$Q$ - количество рангов значения Y меньше текущего из объектов, где ранг значения X больше текущего

> [!example]
> 
>| X   | Y   | P   | Q   |
>| --- | --- | --- | --- |
>|   1  | 2    | 1    | 1    |
>| 2 | 3 |0 |1 |
>| 3 | 1 |0 |0|

#### Проверка значимости
$\tau_{\text{кр}}=z_\text{кр}\sqrt{\frac{2(2n+5)}{9n(n-1)}}$, $z_\text{кр}$ - критическая точка двусторонней крит. области для функции Лапласса.
Если $\vert\tau\vert<\tau_\text{кр}$, корреляция незначимая.

