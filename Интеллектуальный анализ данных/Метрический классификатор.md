---
date: 2024-09-30
tags:
  - theory
  - data_mining
---
Неравенство треугольника *может* нарушаться.

Простейший метрический классификатор - метод $k$ ближайших соседей (kNN), обычно $k$ в случе бинарной классификации берется нечетное.
Более точный метод - метод взвешенных ближаших соседей, вес уменьшается с ростом расстояния.
Часто используемые функции веса (от порядкового номера сравниваемого объекта по возрастанию расстояния): $\omega(i,u)=[i=1]$ - простейший, $\omega(i,u)=[i\leq k]$, $\omega(i,u)=[i\leq k]q^{i}$, $q<1$ - экспоненциально взвешенный.

# Использование ядер сглаживания.
При использовании линейного фильтра, может быть совпадение суммарного веса для нескольких классов. В таких случаях используют ядра.

Теорема Мерсера определяет условия, при которых функция может являться ядром.

> [!NOTE] Теорема Мерсера
> Функция $K(\vec{x_{1}},\vec{x_{2}})$ является ядром тогда и только тогда, когда выполнены условия: $$\begin{cases}
K(\vec{x_{1}},\vec{x_{2}})=K(\vec{x_{2}},\vec{x_{1}})&\text{ - симметричность} \\
\forall g:X\to \mathbb{R}\quad \int_{X}{\int_{X}{K(\vec{x_{1}},\vec{x_{2}})g(\vec{x_{1}})g(\vec{x_{2}})d\vec{x_{1}}d\vec{x_{2}}}}\geq0&\text{ - неотрицательная определенность}
\end{cases}$$

> [!warning]
> Выучить конструктивные методы синтеза ядер.
> Статья [k ближайших соседей](https://proglib.io/p/metod-k-blizhayshih-sosedey-k-nearest-neighbour-2021-07-19), статья от Loginom.
> Посмотреть сверточные нейронные сети, персептроны одно-, многослойные.

