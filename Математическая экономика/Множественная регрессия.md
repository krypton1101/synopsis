---
date: 2024-11-26
tags:
  - theory
  - mathematical_economics
---
Модель множественной линейной регрессии:$$y=a+b_{1}x_{1}+\dots+b_{k}x_{k}+\epsilon$$
где $y$ - отклик (зависимая переменная), $a$ - свободный член, $b_{i}$ - коэффициенты, $x_{i}$ - факторные показатели (зависимые переменные), $\epsilon$ - случайная составляющая.
Уравнение множественной линейной регрессии со чсвободным членом и $k$ независимыми переменными (факторами):$$\hat{y}=a+b_{1}x_{1}+\dots+b_{k}x_{k}$$
Факторы, включаемые во множественную регрессию, должны отвечать следующим требованиям:
1. Они должны быть количественно измеримы. Если необходимо включить в модель качественный фактор, ему нужно придать количественную определенность
2. Факторы не должны быть интеркоррелированы и тем более находиться в точной функциональной связи

##### Интеркоррелированность
Включение в модель факторов с высокой интеркорреляцией, нежелательным может последствиям привести система нормальных уравнений может оказаться плохо обусловленной и повлечь за собой неустойчивость и ненадежность оценок коэффициентов регрессии.

Если между факторами существует высокая корреляция, TO нельзя определить их изолированное влияние на результативный показатель и параметры уравнения регрессии оказываются неинтерпретируемыми.

##### Построение уравнения множественной регрессии. Коэффициент детерминации.
Включаемые во множественную регрессию факторы должны объяснить вариацию независимой переменной.

Если строится модель с набором $m$ факторов, то для нее рассчитывается показатель детерминации $R^{2}$, который фиксирует долю объясненной вариации результативного признака за счет рассматриваемых в регрессии $m$ факторов.

Влияние других, не учтенных в модели факторов, оценивается как $1-R^{2}$ с соответствующей остаточной дисперсией $S^{2}$.

При дополнительном включении в регрессию $m+1$ фактора коэффициент детерминации должен возрастать, а остаточная дисперсия уменьшается:$$R^{2}_{m+1}\geq R^{2}_{m},\quad S^{2}_{m+1}\leq S^{2}_{m}$$
Если же этого не происходит и данныее показатели практически не отличаются друг от друга, то включаемый в анализ фактор $x_{m+1}$ не улучшает модель и практически является лишним.

Насыщение модели лишними факторами не только не снижает величину остаточной дисперсии и не увеличивает показатель детерминации, но и приводит K статистической незначимости параметров регрессии по критерию Стьюдента.

Коэффициенты интеркорреляции (т.е. корреляции между объясняющими переменными) позволяют исключать из модели дублирующие факторы. 
Считается, что две переменные явно коллинеарны, т.е. находятся между собой в линейной зависимости, если $r_{x_{i}x_{j}}\geq 0.7$.

Если факторы явно коллинеарны, то они дублируют друг друга и один из них рекомендуется исключить из регрессии. Предпочтение при этом отдается не фактору, более тесно связанному с результатом, а тому фактору, который при достаточно тесной связи с результатом имеет наименьшую тесноту связи с другими факторами. В этом требовании проявляется специфика множественной регрессии как метода исследования комплексного воздействия факторов в условиях их независимости друг от друга.

###### Проблема мультиколлинеарности
По величине парных коэффициентов корреляции обнаруживается лишь явная коллинеарность факторов. Наибольшие трудности в использовании аппарата множественной регрессии возникают при наличии мультиколлинеарности факторов, когда более чем два фактора связаны между собой линейной зависимостью, т.е. имеет место совокупное воздействие факторов друг на друга. **Наличие мультиколлинеарности факторов может означать, что некоторые факторы будут всегда действовать в унисон.** В результате вариация в исходных данных перестает быть полностью независимой и нельзя оценить воздействие каждого фактора в отдельности.

###### Матрица парных коэффициентов
Для оценки мультиколлинеарности факторов может использоваться определитель матрицы парных коэффициентов корреляции между факторами.

Если бы факторы не коррелировали между собой, то матрица парных коэффициентов корреляции между факторами была бы единичной матрицей, поскольку все недиагональные элементы $r_{x_{i}x_{j}}(i\neq j)$ были бы равны нулю.

Чем ближе к нулю определитель матрицы, тем выше коррелированность факторов.

Существует ряд подходов преодоления сильной межфакторной корреляции.
- Самый простой путь устранения мультиколлинеарности состоит в исключении из модели одного или нескольких факторов.
- Другой подход связан с преобразованием факторов, при котором уменьшается корреляция между ними

##### Отбор факторов
Отбор факторов, включаемых в регрессию, является одним из важнейших этапов практического использования методов регрессии.

Наиболее широкое применение получили следующие методы построения уравнения множественной регрессии:
1. Метод исключения - отсев факторов из полного его набора.
2. Метод включения - дополнительное зведение фактора.
3. Шаговый регрессионный анализ - исключение ранее введенного фактора.

При отборе факторов также рекомендуется пользоваться следующим правилом: число включаемых факторов обычно в 6-7 раз меньше объема совокупности, по которой строится регрессия. Если это соотношение нарушено, то число степеней свободы остаточной дисперсии очень мало. Это приводит к тому, что параметры уравнения регрессии оказываются статистически незначимыми, а F-критерий меньше табличного значения.

## Линейная множественная регрессия
Используется метод наименьших квадратов.

Исследуем исходную функцию $F(a, b_{1},\dots, b_{k})$ на экстремум (ищем частные производные).

Стандартизированная модель множественной регрессии:
$$t_{y}=\beta_{1}t_{x_{1}}+\dots +\beta_{m}t_{x_{m}}+\epsilon$$
где $t$ - стандартизированные переменные: $t_{y}=\frac{y-\overline{y}}{\sigma_{y}}$, $t_{x_{i}}=\frac{x_{i}-\overline{x_{i}}}{\sigma_{x_{i}}}$. Для них среднее значение = 0, а среднее квадратическое отклонение = 1.

Стандартизованные коэффициенты регрессии показывают, на сколько единиц изменится в среднем результат, если соответствующий фактор $x_{i}$ изменится на одну единицу при неизменном среднем уровне других факторов.

![[IMG20241126143343~2.jpg]]

Коэффициенты "чистой" регрессии $b_{i}$ связаны со стандартизированными коэффициентами регрессии $\beta_{i}$ следующим образом: $b_{i}=\beta_{i}\frac{\sigma_{y}}{\sigma_{x_{i}}}$
